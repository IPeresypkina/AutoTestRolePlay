{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E9KWJTFZSdG6-25I-xm-t_hSEytmO88Q",
      "authorship_tag": "ABX9TyPTVE78wKnioiXTqauoZrZs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IPeresypkina/AutoTestRolePlay/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TtC8xV4Eroa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import io\n",
        "import skimage as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import io\n",
        "import tensorflow_datasets as tfds\n",
        "from online_training import *\n",
        "from online_training import online_adaptive_hard_image_generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8Wnd-YRKGPa2",
        "outputId": "0fda5c3d-5468-42f9-8fdf-2a05812b7af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH        = '/content/drive/MyDrive/after_4_bis 2' # Путь к каталогу сохраненного набора данных\n",
        "PATH_SAVE   = '/content/output/history/'                      # Путь к каталогу, в котором будет храниться история\n",
        "PATH_MODEL  = '/content/output/model/2022.05.20/'             # Путь к каталогу, в котором будет храниться модель\n",
        "SIZE        = (224,224,3)                               # Размер входных изображений\n",
        "TEST_SPLIT  = 0.1                                       # Train/test соотношение\n",
        "\n",
        "LOAD_NET    = False                                     # Загрузить сеть из сохраненной модели? Если True NET_NAME и START_EPOCH должны быть уточнены\n",
        "NET_NAME    = '2022.05.20.dogfacenet'                   # Имя, сохраненное в сети\n",
        "START_EPOCH = 0                                         # Начать обучение в указанную эпоху\n",
        "NBOF_EPOCHS = 70                                       # Количество эпох для обучения сети\n",
        "HIGH_LEVEL  = True                                      # Используйте тренировку высокого уровня (метод «fit» кераса)\n",
        "STEPS_PER_EPOCH = 85                                 # Количество шагов за эпоху\n",
        "VALIDATION_STEPS = 30                                   # Количество шагов за проверку"
      ],
      "metadata": {
        "id": "gs1ovdLEG6uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортировать датасет\n",
        "assert os.path.isdir(PATH), '[Error] Provided PATH for dataset does not exist.'\n",
        "\n",
        "print('Loading the dataset...')\n",
        "\n",
        "filenames = np.empty(0)\n",
        "labels = np.empty(0)\n",
        "idx = 0\n",
        "for root,dirs,files in os.walk(PATH):\n",
        "    if len(files)>1:\n",
        "        for i in range(len(files)):\n",
        "            files[i] = root + '/' + files[i]\n",
        "        filenames = np.append(filenames,files)\n",
        "        labels = np.append(labels,np.ones(len(files))*idx)\n",
        "        idx += 1\n",
        "assert len(labels)!=0, '[Error] No data provided.'\n",
        "\n",
        "print('Done.')\n",
        "\n",
        "print('Общее количество импортированных изображений: {:d}'.format(len(labels)))\n",
        "# количество классов собак\n",
        "nbof_classes = len(np.unique(labels))\n",
        "print('Общее количество классов: {:d}'.format(nbof_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLVxMzpSH_Ef",
        "outputId": "1b8e1fd3-8b98-4ac5-ae13-bba8d1f3aa51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n",
            "Done.\n",
            "Общее количество импортированных изображений: 8363\n",
            "Общее количество классов: 1393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделить набор данных на обучающий и тестовый.\n",
        "\n",
        "nbof_test = int(TEST_SPLIT*nbof_classes)\n",
        "\n",
        "keep_test = np.less(labels,nbof_test)\n",
        "keep_train = np.logical_not(keep_test)\n",
        "\n",
        "filenames_test = filenames[keep_test]\n",
        "labels_test = labels[keep_test]\n",
        "\n",
        "filenames_train = filenames[keep_train]\n",
        "labels_train = labels[keep_train]\n",
        "\n",
        "print(\"Количество обучающих данных: \" + str(len(filenames_train)))\n",
        "print(\"Количество обучающих классов: \" + str(nbof_classes-nbof_test))\n",
        "print(\"Количество тестовых данных: \" + str(len(filenames_test)))\n",
        "print(\"Количество тестовых классов: \" + str(nbof_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbCQ_99hIYAs",
        "outputId": "6e8ddd13-3d48-4c54-8f3d-4d140268274d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество обучающих данных: 7659\n",
            "Количество обучающих классов: 1254\n",
            "Количество тестовых данных: 704\n",
            "Количество тестовых классов: 139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение потерь.\n",
        "\n",
        "alpha = 0.3\n",
        "def triplet(y_true,y_pred):\n",
        "    \n",
        "    a = y_pred[0::3] # с элементом под индексом 0  и брать эелементы с шагом 3\n",
        "    p = y_pred[1::3] # с элементом под индексом 1  и брать эелементы с шагом 3\n",
        "    n = y_pred[2::3] # с элементом под индексом 2  и брать эелементы с шагом 3\n",
        "    \n",
        "    ap = K.sum(K.square(a-p),-1)\n",
        "    an = K.sum(K.square(a-n),-1)\n",
        "\n",
        "    return K.sum(tf.nn.relu(ap - an + alpha))\n",
        "\n",
        "def triplet_acc(y_true,y_pred):\n",
        "    a = y_pred[0::3]\n",
        "    p = y_pred[1::3]\n",
        "    n = y_pred[2::3]\n",
        "    \n",
        "    ap = K.sum(K.square(a-p),-1)\n",
        "    an = K.sum(K.square(a-n),-1)\n",
        "    \n",
        "    return K.less(ap+alpha,an)"
      ],
      "metadata": {
        "id": "Pud3nbSgIYwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение модели.\n",
        "# для продолжения обучения\n",
        "if LOAD_NET:\n",
        "    print('Loading model from {:s}{:s}.{:d}.h5 ...'.format(PATH_MODEL,NET_NAME,START_EPOCH))\n",
        "\n",
        "    model = tf.keras.models.load_model(\n",
        "        '{:s}{:s}.{:d}.h5'.format(PATH_MODEL,NET_NAME,START_EPOCH),\n",
        "        custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})\n",
        "\n",
        "    print('Done.')\n",
        "else:\n",
        "    from tensorflow.keras import Model\n",
        "    from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D, DepthwiseConv2D\n",
        "    from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
        "\n",
        "    \"\"\"\n",
        "    Model number 12: Paper version: a modified ResNet with Dropout layers and without bottleneck layers\n",
        "    \"\"\"\n",
        "\n",
        "    print('Определение модели {:s} ...'.format(NET_NAME))\n",
        "\n",
        "    emb_size = 32\n",
        "    # размер входных изображений\n",
        "    inputs = Input(shape=SIZE)\n",
        "    print(inputs)\n",
        "    \n",
        "    # Слой двумерной свертки\n",
        "    # use_bias - Boolean, указывает, использует ли слой вектор смещения.\n",
        "    # activation - Функция активации для использования. Если вы ничего не укажете, активация не будет применена.\n",
        "        # relu - Применяет функцию активации выпрямленного линейного блока.\n",
        "    # padding - один из \"valid\" или \"same\"(без учета регистра).\n",
        "        # \"valid\"значит без прокладки.\n",
        "        # \"same\"приводит к равномерному заполнению нулями слева/справа или вверх/вниз от ввода. Когда padding=\"same\"и strides=model1, выход имеет тот же размер, что и вход.\n",
        "    x = Conv2D(16, (7, 7), (2, 2), use_bias=False, activation='relu', padding='same')(inputs)\n",
        "    # Слой, который нормализует свои входные данные.\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((3,3))(x)\n",
        "    \n",
        "    for layer in [16,32,64,128,512]:\n",
        "    \n",
        "        x = Conv2D(layer, (3, 3), strides=(2,2), use_bias=False, activation='relu', padding='same')(x)\n",
        "        r = BatchNormalization()(x)\n",
        "        # r = Dropout(0.25)(r)\n",
        "    \n",
        "        x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
        "        x = BatchNormalization()(x)\n",
        "        r = Add()([r,x])\n",
        "        # r = Dropout(0.25)(r)\n",
        "    \n",
        "        x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Add()([r,x])\n",
        "        # r = Dropout(0.25)(r)\n",
        "    \n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(emb_size, use_bias=False)(x)\n",
        "    # Слой Lambda существует для того, чтобы произвольные выражения можно было использовать\n",
        "    # как Layer при построении Sequential моделей функционального API.\n",
        "    # L2 нормализует вложения\n",
        "    outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs,outputs)\n",
        "    \n",
        "    # Настройка модели с потерями и показателями\n",
        "    model.compile(loss=triplet,\n",
        "                optimizer='adam',\n",
        "                metrics=[triplet_acc])\n",
        "    print(model.summary())\n",
        "    print('Done.')\n",
        "\n",
        "    # dogfacenet_v11: VGG like\n",
        "    # emb_size = 32\n",
        "\n",
        "    # from tensorflow.keras.models import Sequential\n",
        "    # from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "    # from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
        "\n",
        "    # model = Sequential()\n",
        "    # model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
        "    # model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    # model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    # model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    # model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    # model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(512, activation='relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "    # model.add(Dense(emb_size, use_bias=False))\n",
        "    # model.add(Lambda(lambda x: tf.nn.l2_normalize(x, axis=-1)))\n",
        "\n",
        "    # model.compile(loss=triplet,\n",
        "    #               optimizer='adam',\n",
        "    #               metrics=[triplet_acc])\n",
        "    # model.summary()\n",
        "    # print('Done.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3lNDs9qIbPa",
        "outputId": "94c1b3ca-921e-4c49-bfe8-47c33706dc41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Определение модели 2022.05.20.dogfacenet ...\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 112, 112, 16  2352        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 112, 112, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 37, 37, 16)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 19, 19, 16)   2304        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 19, 19, 16)  64          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 19, 19, 16)   2304        ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 19, 19, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 19, 19, 16)   0           ['batch_normalization_1[0][0]',  \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 19, 19, 16)   2304        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 19, 19, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 16)   0           ['add[0][0]',                    \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 10, 10, 32)   4608        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 10, 10, 32)   9216        ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 32)   0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 10, 10, 32)   9216        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 10, 10, 32)  128         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 32)   0           ['add_2[0][0]',                  \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 5, 5, 64)     18432       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 5, 5, 64)    256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 5, 5, 64)     36864       ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 5, 5, 64)    256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 5, 5, 64)     0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 5, 5, 64)     36864       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 5, 5, 64)    256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 5, 5, 64)     0           ['add_4[0][0]',                  \n",
            "                                                                  'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 3, 3, 128)    73728       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 3, 3, 128)   512         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 3, 3, 128)    147456      ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 3, 3, 128)   512         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 3, 3, 128)    0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 3, 3, 128)    147456      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 3, 3, 128)   512         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 3, 3, 128)    0           ['add_6[0][0]',                  \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 2, 2, 512)    589824      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 2, 2, 512)    2359296     ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 512)    0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 2, 2, 512)    2359296     ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 512)    0           ['add_8[0][0]',                  \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 512)         0           ['add_9[0][0]']                  \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 512)          0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           16384       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,826,992\n",
            "Trainable params: 5,822,448\n",
            "Non-trainable params: 4,544\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import filters\n",
        "import io\n",
        "import skimage as sk"
      ],
      "metadata": {
        "id": "7N9JoWV8gFSF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TU8qPSrtiBvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard training: высокий уровень реализации\n",
        "histor = []\n",
        "crt_loss = 0.6\n",
        "crt_acc = 0\n",
        "batch_size = 3*10\n",
        "nbof_subclasses = 40\n",
        "\n",
        "# Создание папок для сохранения\n",
        "if not os.path.isdir(PATH_MODEL):\n",
        "  os.makedirs(PATH_MODEL)\n",
        "if not os.path.isdir(PATH_SAVE):\n",
        "  os.makedirs(PATH_SAVE)\n",
        "\n",
        "# Исправлена ошибка: модели keras должны быть инициализированы обучением на одной партии\n",
        "# for images_batch,labels_batch in online_adaptive_hard_image_generator(\n",
        "#     filenames_train,\n",
        "#     labels_train,\n",
        "#     model,\n",
        "#     crt_acc,\n",
        "#     batch_size,\n",
        "#     nbof_subclasses=nbof_subclasses):\n",
        "#     h = model.train_on_batch(images_batch,labels_batch)\n",
        "#     break\n",
        "\n",
        "\n",
        "for i in range(START_EPOCH,START_EPOCH+NBOF_EPOCHS):\n",
        "  print(\"Beginning epoch number: \"+str(i))\n",
        "\n",
        "  hard_triplet_ratio = np.exp(-crt_loss * 10 / batch_size)\n",
        "  nbof_hard_triplets = int(batch_size//3 * hard_triplet_ratio)\n",
        "\n",
        "  print(\"Current hard triplet ratio: \" + str(hard_triplet_ratio))\n",
        "\n",
        "  histor += [model.fit(\n",
        "    online_adaptive_hard_image_generator(filenames_train,labels_train,model,crt_loss,batch_size,nbof_subclasses=nbof_subclasses),\n",
        "    validation_data=image_generator(filenames_test,labels_test,batch_size,use_aug=False),\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=1)]\n",
        "\n",
        "  # histor += [model.fit_generator(\n",
        "  #   online_adaptive_hard_image_generator(filenames_train,labels_train,model,crt_loss,batch_size,nbof_subclasses=nbof_subclasses),\n",
        "  #   steps_per_epoch=STEPS_PER_EPOCH,\n",
        "  #   epochs=1,\n",
        "  #   validation_data=image_generator(filenames_test,labels_test,batch_size,use_aug=False),\n",
        "  #   validation_steps=VALIDATION_STEPS)]\n",
        "\n",
        "  crt_loss = histor[-1].history['loss'][0]\n",
        "  crt_acc = histor[-1].history['triplet_acc'][0]\n",
        "\n",
        "  # Save model\n",
        "  model.save('{:s}{:s}.{:d}.h5'.format(PATH_MODEL,NET_NAME,i))\n",
        "\n",
        "  # Save history\n",
        "  loss = np.empty(0)\n",
        "  val_loss = np.empty(0)\n",
        "  acc = np.empty(0)\n",
        "  val_acc = np.empty(0)\n",
        "\n",
        "  for history in histor:\n",
        "    loss = np.append(loss,history.history['loss'])\n",
        "    val_loss = np.append(val_loss,history.history['val_loss'])\n",
        "    acc = np.append(acc,history.history['triplet_acc'])\n",
        "    val_acc = np.append(val_acc,history.history['val_triplet_acc'])\n",
        "\n",
        "  history_ = np.array([loss,val_loss,acc,val_acc])\n",
        "  np.save('{:s}{:s}.{:d}.npy'.format(PATH_SAVE,NET_NAME,i),history_)\n",
        "\n",
        "h, w, c = SIZE\n",
        "images_test = np.empty((len(filenames_test), h, w, c))\n",
        "for i, f in enumerate(filenames_test):\n",
        "  images_test[i] = sk.io.imread(f)\n",
        "  images_test = np.empty((len(filenames_test), h, w, c))\n",
        "\n",
        "results = model.predict([images_test, labels_test])\n",
        "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for img, labels in tfds.as_numpy(filenames_test):\n",
        "  [out_m.write(str(x) + \"\\n\") for x in labels]\n",
        "out_m.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "m9UEVAnMImVD",
        "outputId": "7eb6653c-1ca2-4731-b78c-58e58a026695"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning epoch number: 0\n",
            "Current hard triplet ratio: 0.8187307530779818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/online_training.py:214: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  steps=int(np.ceil(len(subfilenames)/32)))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-74ef2a11d96f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     epochs=1)]\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# histor += [model.fit_generator(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/online_training.py\u001b[0m in \u001b[0;36monline_adaptive_hard_image_generator\u001b[0;34m(filenames, labels, model, loss, batch_size, nbof_subclasses, use_aug, datagen)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0msublabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         predict = model.predict_generator(predict_generator(subfilenames, 32),\n\u001b[0;32m--> 214\u001b[0;31m                                           steps=int(np.ceil(len(subfilenames)/32)))\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/online_training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(filenames, batch_size)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \"\"\"\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mimages_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mimages_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/online_training.py\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;31m# images[i] = sk.io.imread(f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'skimage' has no attribute 'io'"
          ]
        }
      ]
    }
  ]
}